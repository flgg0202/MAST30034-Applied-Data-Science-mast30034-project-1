{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/08/19 06:38:19 WARN Utils: Your hostname, flgg resolves to a loopback address: 127.0.1.1; using 172.28.210.36 instead (on interface eth0)\n",
      "23/08/19 06:38:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/19 06:38:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/19 06:38:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"External Data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '4g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('../data/raw/NYPD_crime_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMPLNT_NUM           271717\n",
       "ADDR_PCT_CD          271683\n",
       "BORO_NM              271717\n",
       "CMPLNT_FR_DT         271717\n",
       "CMPLNT_FR_TM         271717\n",
       "CMPLNT_TO_DT         253642\n",
       "CMPLNT_TO_TM         271717\n",
       "CRM_ATPT_CPTD_CD     271717\n",
       "HADEVELOPT           271717\n",
       "JURIS_DESC           271717\n",
       "KY_CD                271717\n",
       "LAW_CAT_CD           271717\n",
       "LOC_OF_OCCUR_DESC    271717\n",
       "OFNS_DESC            271717\n",
       "PARKS_NM             271717\n",
       "PD_CD                271516\n",
       "PD_DESC              271717\n",
       "PREM_TYP_DESC        271717\n",
       "RPT_DT               271717\n",
       "Lat_Lon              271712\n",
       "X_COORD_CD           271712\n",
       "Y_COORD_CD           271712\n",
       "Latitude             271712\n",
       "Longitude            271712\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the train data and test data\n",
    "csv['CMPLNT_FR_DT'] = pd.to_datetime(csv['CMPLNT_FR_DT'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "start_date = '2022-09-01'\n",
    "end_date = '2023-03-31'\n",
    "\n",
    "filtered_df = csv[(csv['CMPLNT_FR_DT'] >= start_date) & (csv['CMPLNT_FR_DT'] <= end_date)]\n",
    "\n",
    "\n",
    "test_start_date = '2023-04-01'\n",
    "test_end_date = '2023-04-30'\n",
    "\n",
    "test_cdf = csv[(csv['CMPLNT_FR_DT'] >= test_start_date) & (csv['CMPLNT_FR_DT'] <= test_end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMPLNT_NUM           40562\n",
       "ADDR_PCT_CD          40562\n",
       "BORO_NM              40562\n",
       "CMPLNT_FR_DT         40562\n",
       "CMPLNT_FR_TM         40562\n",
       "CMPLNT_TO_DT         40562\n",
       "CMPLNT_TO_TM         40562\n",
       "CRM_ATPT_CPTD_CD     40562\n",
       "HADEVELOPT           40562\n",
       "JURIS_DESC           40562\n",
       "KY_CD                40562\n",
       "LAW_CAT_CD           40562\n",
       "LOC_OF_OCCUR_DESC    40562\n",
       "OFNS_DESC            40562\n",
       "PARKS_NM             40562\n",
       "PD_CD                40562\n",
       "PD_DESC              40562\n",
       "PREM_TYP_DESC        40562\n",
       "RPT_DT               40562\n",
       "Lat_Lon              40562\n",
       "X_COORD_CD           40562\n",
       "Y_COORD_CD           40562\n",
       "Latitude             40562\n",
       "Longitude            40562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna\n",
    "cols_to_check = ['ADDR_PCT_CD', 'BORO_NM', 'CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'CMPLNT_TO_DT', 'CMPLNT_TO_TM']\n",
    "\n",
    "filtered_df = filtered_df.dropna(subset=cols_to_check)\n",
    "\n",
    "test_cdf = test_cdf.dropna(subset=cols_to_check)\n",
    "\n",
    "filtered_df.count()\n",
    "test_cdf.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the geo data for merge\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "sf = gpd.read_file(\"../data/landing/taxi_zones.shp\")\n",
    "zones = pd.read_csv(\"../data/landing/taxi+_zone_lookup.csv\")\n",
    "sf['geometry'] = sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "sf.head()\n",
    "\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pd.merge(zones, sf, on='LocationID', how='inner')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined the data according to the taxi zone data\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(filtered_df.Longitude, filtered_df.Latitude)]\n",
    "points_gdf = gpd.GeoDataFrame(filtered_df, geometry=geometry)\n",
    "\n",
    "test_geometry = [Point(xy) for xy in zip(test_cdf.Longitude, test_cdf.Latitude)]\n",
    "test_points_gdf = gpd.GeoDataFrame(test_cdf, geometry=test_geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flgg/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/tmp/ipykernel_363131/204773563.py:1: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs + ...\n",
      "\n",
      "  joined = gpd.sjoin(points_gdf, sf, how=\"inner\", op=\"within\")\n",
      "/home/flgg/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/tmp/ipykernel_363131/204773563.py:4: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs + ...\n",
      "\n",
      "  test_joined = gpd.sjoin(test_points_gdf, sf, how=\"inner\", op=\"within\")\n"
     ]
    }
   ],
   "source": [
    "# generate and save the geo train and test data\n",
    "joined = gpd.sjoin(points_gdf, sf, how=\"inner\", op=\"within\")\n",
    "joined.to_csv('../data/curated/joined.csv', index=False)\n",
    "\n",
    "test_joined = gpd.sjoin(test_points_gdf, sf, how=\"inner\", op=\"within\")\n",
    "test_joined.to_csv('../data/curated/test_joined.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
